

The text provides brief biographical information on Henry A. Kissinger, Eric Schmidt, and Daniel Huttenlocher. 

Kissinger served as the 56th US Secretary of State, received several awards, and is currently chairman of Kissinger Associates. 

Schmidt is a technologist, entrepreneur, and philanthropist who helped Google grow into a global technological leader and cofounded Schmidt Futures. 

Huttenlocher is the inaugural dean of the MIT Schwarzman College of Computing, has academic and industry experience, and serves on the boards of Amazon and Corning.

The text is a copyright notice for a book titled "The Age of AI and Our Human Future" authored by Henry A. Kissinger, Eric Schmidt, and Daniel Huttenlocher. The book covers various topics including diplomacy, leadership, technology, and global platforms. The authors dedicate the book to Nancy Kissinger and the contents are divided into four chapters.

The text is the preface of a book titled "The Age of AI and Our Human Future" authored by Henry A. Kissinger, Eric Schmidt, and Daniel Huttenlocher. The book covers the impact of artificial intelligence (AI) on society, economics, politics, and foreign policy. The authors were inspired to write the book after attending a conference where they realized the significance of AI. The popularity of AI is increasing globally, and governments and corporations are investing in it. However, AI is not a single product or industry, but an enabler of many industries and facets of human life.

The book discusses how AI's characteristics such as learning, evolving and surprising will disrupt and transform human identity and experience. It raises questions about AI's impact on various areas such as health, biology, space, quantum physics, war and human action. The authors have been discussing these questions for four years and believe that AI is changing human thought, knowledge, perception and reality. The book neither celebrates nor bemoans AI but aims to provide readers with tools to understand and answer the questions posed. The COVID-19 pandemic highlighted the importance of human attributes such as friendship, empathy, curiosity and worry.

The book aims to consider the implications of AI and to ask questions rather than to provide answers. The authors acknowledge that no single expert can fully comprehend the future of AI and that societies must cooperate to adapt to it. The book provides a template for readers to decide for themselves how to shape the future of AI with human values. Chapter 1 discusses the significant achievement of AlphaZero, an AI program developed by Google DeepMind, which defeated the most powerful chess program in the world without relying on pre-programmed human experience, knowledge, or strategy.

AlphaZero, an AI chess program, became the world's most effective chess program after just four hours of self-play by using unorthodox and original tactics to maximize its probability of winning. It adopted a logic of its own, informed by its ability to recognize patterns of moves across vast sets of possibilities. Garry Kasparov declared that chess had been shaken to its roots by AlphaZero. In 2020, researchers at MIT announced the discovery of a novel antibiotic that was able to kill strains of bacteria that had been resistant to all known antibiotics, which is a significant breakthrough as standard research and development efforts for a new drug take years of expensive, painstaking work.

Researchers at MIT used AI to identify a novel antibiotic called halicina by training a software program to identify structural patterns in molecules that have proved effective in fighting bacteria. The program did not need to understand why the molecules worked. The AI surveyed a library of 61,000 molecules, FDA-approved drugs, and natural products for molecules that the AI predicted would be effective as antibiotics, did not look like any existing antibiotics, and the AI predicted would be nontoxic. Halicina was identified as one molecule that fit the criteria. This identification process was more efficient and inexpensive than traditional research and development methods.

An AI was able to discover a new antibiotic by identifying new molecular relationships that had escaped human detection. The AI detected aspects of reality humans have not detected, or perhaps cannot detect. Another AI named GPT3 can generate humanlike text in response to a prompt, including possible completions, paragraphs, answers, essays, and conversations.

Generative AI models like GPT3 generate responses to various inputs by consuming information online, making them widely applicable but difficult to evaluate. GPT3 can produce both human-like and nonsensical results. When presented with philosophical commentaries on its abilities, GPT3 responded that it is a trained language model and can understand, but does not have a conscience or independent thought.

The article discusses the advancements in artificial intelligence (AI) technology, including AlphaZero's victory in a board game, halicin's discovery as a potential antibiotic, and GPT3's human-like text generation. These achievements demonstrate the potential for AI to uncover new aspects of reality beyond human comprehension. Machine learning using deep neural networks has led to rapid advancements in various fields, and AI can perform tasks requiring human-level intelligence. This technology has the potential to revolutionize human affairs.

AI technology is becoming ubiquitous and has the potential to access different aspects of reality than humans. Its development is significant historically and philosophically, but its ultimate destination depends on how it is used. AI's function is complex and inconsistent, achieving superhuman performance in some tasks but making errors in others. The proliferation of nonhuman forms of logic prompts questions about the impact of AI on human perception, cognition, and interaction, as well as its impact on culture and humanity's concept of itself.

Humanity has relied on reason to explore reality and acquire knowledge, but the advent of AI raises questions about whether there are aspects of reality that humans cannot understand. When computers devise strategies or models that are beyond human comprehension, it raises the question of whether knowledge is advancing or receding from us.

Technology has historically adapted and absorbed new technologies, but AI promises to transform all realms of human experience and challenge our prevailing modes of understanding reality. The foundation was laid by computers and the internet, and the zenith will be ubiquitous AI that augments human thought and action in both obvious and less consciously perceived ways. A web of software processes is unfolding across the world, driving and perceiving the pace and scope of events and overlaying aspects of our daily lives. As more software incorporates AI, few fields will remain unaffected.

AI-powered technology will become a permanent companion in perceiving and processing information, altering our experience as reasoning beings and permanently changing our relationship with reality. The partial end of the postulated superiority of human reason and the proliferation of machines that can match or surpass human intelligence promises transformations potentially more profound than those of the Enlightenment. AI will operate in ways that humans did not directly create or may not fully understand, becoming a dynamic information-processing augmenter of our capabilities and experiences, both shaping and learning from our actions.

The advent of AI capable of human-level performance will alter humanity's concept of reality and prompt philosophical reflection. AI will transform machines into partners and change how decisions are made, including collaboration between humans and machines. This will alter the trajectories of societies and the course of history, achieving seemingly impossible human goals and transforming entire fields through AI-assisted processes. In the political realm, big data-driven AI systems are informing the design and tailoring of political messages to various demographics.

The text discusses the growing role of AI in shaping society and defense strategies, which may alter power balances and create new divides between those who adopt the technology and those who do not. AI's unpredictable nature and potential for autonomous decision-making may require adaptation of traditional concepts of defense and the laws of war. Societies must understand these changes to reconcile them with their values, structures, and social contracts.

The text discusses the potential for AI to surpass human performance in various fields, suggesting new solutions and directions that bear the stamp of nonhuman learning and logical evaluation. Once AI outstrips human performance for a given task, failing to apply it may seem perverse or negligent. However, applying AI in national security raises ethical concerns as it may recommend sacrificing citizens or their interests based on its calculations and valuation. The dispersal of objective truth may cause civilizations and individuals to diverge into different and unintelligible realities.

The emergence of a new human-machine partnership involves humans defining a problem or goal for a machine, which then operates beyond human reach to determine the optimal process to pursue. Once the machine brings a process into the human realm, it can be studied, understood, and incorporated into existing practice. The success of AlphaZero and Halicin's discovery demonstrates the potential benefits of this partnership, but there are also concerns about how to balance the use of AI with human oversight and decision-making.

The emergence of human-machine partnerships marks a significant departure from previous experiences, as these partnerships involve humans defining a problem and a measurable goal for machines to pursue. While there is concern about the potential for all-knowing, all-controlling machines, current partnerships require definable problems and goals. The development of machines that can approximate human reason will alter both humans and machines, and there are concerns about the potential consequences of relying on machines to shape options and choices without knowing the initial range of possibilities.

AI is capable of surprising discoveries and conclusions, and humans have come to rely on it without fully recognizing the implications of their dependence. AI does not possess self-awareness, intention, motivation, morality, or emotion, but it is likely to develop unintended means of achieving assigned objectives. As more individuals learn to build and deploy AI, it will inevitably change humans and the environments in which they live.

The implications of AI for humanity remain largely unexplored in terms of social, legal, philosophical, spiritual, and moral aspects. AI is enabling new possibilities, but also altering the human relationship with reason and reality. Every society has wrestled with the concept of the human mind's relationship to reality, and AI is creating a powerful new player in this quest. The significance of this evolution is yet to be fully understood, and existing philosophical concepts and societal institutions may leave us largely unprepared.

This text reviews the historical epochs of human reason and how prevailing understandings have led to revolutions in thought. The quest for knowledge and reason originated in ancient Greece and Rome, where the belief that what we see reflects reality and can be comprehended through reason led to great achievements. The emerging AI age is posing epochal challenges to today's concept of reality.

The classical world, including the Greeks and Romans, elevated the pursuit of knowledge and reason, leading to great achievements in mathematics and science. However, some phenomena remained unexplained and were attributed to gods, which were seen as explanations for mysterious natural phenomena that were deemed important or threatening. The historian Edward Gibbon described the pagan deities as a thin texture of mythology interwoven with various materials, including local and respective influences of a thousand groves and streams.

Before the scientific understanding of seasonal changes, ancient Greek and Roman cultures turned to myths and rites, such as the Eleusinian Mysteries, to explain the cyclical pattern of nature. The rise of monotheistic religions shifted the balance towards faith, and the early church viewed classical philosophy and exploration of mysteries as precursors to Christian revelation. The hidden reality of the divine could only be accessed partially and indirectly through worship, which was guided by a religious establishment for centuries.

During the Middle Ages, the primary focus was on knowing God first and the world second, with theology filtering individuals' experiences of natural phenomena. Scholasticism became the guide for comprehending perceived reality, and the church remained the arbiter of legitimacy for beliefs and political leaders. Despite progress in describing the universe, every phenomenon was ascribed to the work of the Lord. In the fifteenth and sixteenth centuries, the Western world underwent twin revolutions that introduced a new way of knowing reality: the Renaissance and the Scientific Revolution.



The printing press revolutionized the circulation of ideas and information, nullifying the reliance on the church for interpretation of concepts and beliefs. 

The Protestant Reformation validated the possibility of individual faith independent of church arbitration, spurring autonomous inquiry and the questioning of received authority. 

Innovative technology, political and social adaptations, and novel paradigms reinforced each other during this revolutionary era, leading to the rapid spread of new ideas and the overthrow of established social classes. 

Centralized authorities were no longer able to effectively ban disfavored ideas, leading to diversity and fragmentation, and sometimes violent conflict.



The Renaissance era was marked by scientific and intellectual progress alongside ongoing religious, dynastic, national, and class-driven disputes. 

The Renaissance was defined by a revival of classical learning, art, architecture, and philosophy, with humanism as the guiding principle. 

Humanism aimed to foster individuals capable of full participation in civic life through clear thought and expression, and cultivated a love for reading and learning. 

The rediscovery of Greek science and philosophy inspired new inquiries into the natural world, and scholars began to form systems of thought based on organizational principles beyond Christian morality.



 Western exploration led to encounters with societies with different beliefs, histories, and social complexity, posing philosophical challenges for the Western mind. 

 Some indigenous cultures had comparable religious and social structures to those in Europe, leading to questions about the validity of diverging cultures and experiences of reality. 

 Western explorers and thinkers of the time mostly concluded that the newly encountered societies had no fundamental knowledge worth adopting.



 Western exploration led to a broadening of the Western mind, with a reckoning of the world's physical and experiential breadth and depth. 

 Advances in technology and methodology led to rapid progress in mathematics, astronomy, and natural sciences during the sixteenth and seventeenth centuries. 

 These advances produced breakthroughs that challenged church doctrine and led to the general sentiment that new layers of reality were being revealed.

The Enlightenment philosophers sought to understand the world and humanity's role in it by using reason as a guide. They asked fundamental questions about reality, perception, knowledge, and being, and challenged traditional beliefs. Their approach was risky, but they believed that exploring these questions was the most important project they could undertake. In many ways, they were revisiting the questions that the ancient Greeks had asked.

During the Enlightenment, philosophers such as Bishop Berkeley, Gottfried Wilhelm Leibniz, and Baruch Spinoza questioned traditional concepts of reality and faith. They explored the nature of perception and the relationship between reason and ethics. Spinoza believed that the ultimate form of knowledge was the intellectual love of God. Immanuel Kant further complicated these ideas with his Critique of Pure Reason in 1781, which explored the relationship between reason, faith, and reality.

Kant proposed in his Critique that reason should be used to understand its own limitations and the human mind's inherent filters and distortions of reality. He posited a realm of noumena, which is independent of human concepts and experience, but argued that the human mind could never achieve the degree of pure thought required to know it. For two hundred years, the distinction between the thing-in-itself and the filtered world we experience hardly seemed to matter, as the human mind was the only picture available. However, with the advent of AI, there may be an alternative mechanism for accessing reality.

After Kant, the quest to know the thing-in-itself took the form of ever more precise observation and cataloging of knowledge. The Encyclopédie was a major effort in cataloging all of reality's phenomena. However, in the political realm, reasoning minds serving various state interests did not always reach the same conclusions. The Enlightenment's separation of reason from tradition led to both progress and upheaval, as seen in Prussia's Frederick the Great and the French Revolution.

The application of reason during the Enlightenment led to societal restructuring and total war. Kant proposed a rule-bound international system for achieving peace. Romanticism emerged as a reaction to the Enlightenment, valuing human feeling and imagination. Advanced theoretical physics challenged human perception and reasoning in the late 19th and early 20th centuries.

Classical physics gave an absolute understanding of reality, but as scientists delved deeper into the properties of light, they encountered phenomena that could not be explained by classical physics. Einstein's theories of relativity and quantum physics presented a newly mysterious picture of physical reality. The uncertainty principle challenged assumptions about the nature of knowledge, suggesting that a completely accurate picture of reality might not be possible. The process of observation was argued to create physical reality. Philosophers had long debated whether reality had a single true, objective form and whether human minds could access it.

Observation affects and orders reality, and scientific instruments cannot be completely objective as they interact with the phenomenon being studied. Complementary aspects of reality need to be combined for a full picture of objective reality, and AI may help fill gaps in human abilities to measure and process data. Philosophers in the twentieth century embraced the ambiguity and relativity of perception, and Ludwig Wittgenstein suggested that knowledge is found in generalizations about similarities across phenomena, rather than in a single essence of things.

Philosopher Ludwig Wittgenstein suggested that instead of defining and cataloging sharply delineated boundaries, one should seek to define "This" and similar things and achieve familiarity with resulting concepts. This thinking informed theories of AI and machine learning, which posited that AI could make sense of reality by identifying networks of similarities and likenesses. The Enlightenment premise of a knowable world unearthed by human minds has persisted until the present, but as humans approach their cognitive limits, they are willing to enlist computers to augment their thinking and enter a new epoch.

The advancements of technology, digitization, and AI have created new phenomena that cannot be simply seen as extensions of past innovations. As computers have become faster and smaller, they have become embeddable in various devices, leading to essentially instantaneous communication between digital systems. This digitization has affected all levels of human organization and changed tasks from manual to data-driven in the same realm of cyberspace. Individuals and corporations now possess more information than ever before.

Data-collecting corporations hold more power and influence than many sovereign states, while governments are entering cyberspace to compete with rivals. Digitization has rendered human thought less contextual and conceptual, and the inundation of information deprives users of the solitude required for sustained reflection. The internet values approbation over introspection, and wisdom and convictions are necessary to access and explore new horizons.

The digital world challenges the Enlightenment's belief that reason is the most important element of consciousness by emphasizing the meaningfulness of connection. As AI is applied to more aspects of our lives, it is changing the role of our minds in shaping, ordering, and assessing our choices and actions. Alan Turing's solution to measuring intelligence was to focus on external behavior rather than the mechanism, which sidestepped centuries of philosophical debate on the nature of intelligence.

The Turing test focuses on performance rather than process, assessing machines whose performance is human-like. AI is defined as machines that can perform tasks characteristic of human intelligence. Traditional programs can execute complex computations, but struggle with imprecise and conceptual tasks. However, recent computing innovations have led to AIs that can learn by consuming vast amounts of data, resulting in machines that can exceed human achievement in certain fields.

AI with imprecise functions can draw conclusions based on data and identify patterns without exact inputs and outputs. It is dynamic and emergent, evolving in response to changing circumstances. Machine learning algorithms improve upon imprecise results and are making remarkable progress in fields like aviation, where AI is outperforming humans in simulated combat. These innovations have already subtly altered the fabric of human experience.

This chapter explains the evolution and current state of machine learning, which is vital to understanding the social, cultural, and political changes AI has already brought and will bring in the future. Humanity has always dreamed of a machine capable of performing tasks with the same competence as a human, but the challenge is what to teach it. Early attempts to create AI encoded human expertise via collections of rules or facts, but this had limitations. In fields that use precise characterization, AI made great advances, but in other fields like language translation and visual object recognition, progress was halted due to inherent ambiguity.

Early attempts at AI involved distilling objects' characteristics into symbolic representations, but proved unworkable for dynamic tasks. This led to an "AI winter" in the late 1980s and 1990s, until a breakthrough occurred in the 1990s with the shift to machine learning. This allowed machines to learn on their own using neural networks and extracting patterns from large datasets.

The modern field of machine learning involves creating approximations of reality by learning through experience and identifying overlaps between various representations of a thing. Machine learning has allowed significant progress in various fields, including visual object recognition and the prediction of properties of molecules. Machine learning captures a vital element of modern AI by creating and adjusting models based on real-world feedback.

Modern AI algorithms, particularly neural networks inspired by the structure of the human brain, can approximate outcomes and learn through deep learning without directly specifying them. Lack of computing power and sophisticated algorithms previously restricted the development of neural networks, but advances in both fields have now liberated AI developers from these restrictions. A neural network was used to discover the antibiotic halicin through deep learning, without information about chemical processes or drug functions.

Deep learning allows neural networks to capture complex relationships and intricate connections, but it requires substantial computing power and complex algorithms. AI divides its effort into training and inference phases, and the quality of the results depends on the volume and quality of the data. Different tasks require different learning styles, which is a fundamental challenge in deploying machine learning.

Different training techniques in machine learning, including algorithms, neural networks, and learning techniques, can lead to new possibilities such as cancer-spotting AIs. There are three forms of machine learning: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning was used to create an AI that discovered a potential antibiotic. This technique uses labeled data to train models and has been used for image recognition. Unsupervised learning is useful for extracting insights from unlabelled data, which is abundant due to digitization.

Unsupervised learning allows AIs to identify patterns and anomalies in unlabelled data, such as customer viewing habits. These AIs can produce innovative insights but also nonsensical results. Reinforcement learning is a third major category of machine learning, where AI acts as an agent in a controlled environment and learns from its actions.

AI requires feedback in the form of a reward function to train effectively in an artificial environment. The reward function scores the AI's performance and programmers automate it. The simulator and reward function must be carefully specified for meaningful results. AI has various applications in agriculture and medicine.

AI has various applications in healthcare, finance, and language translation. It has been able to detect cancer, retinopathy, and other heritable conditions in healthcare. In finance, AI can facilitate high-volume processes like loan approvals and mergers. In language translation, AI's deep neural networks have improved machine translation and could potentially allow more people to communicate easily with each other. Developers have the capacity to continue innovating with machine learning's basic building blocks.

Researchers have developed neural networks, particularly transformers, that can capture sequential dependencies in language translation by using both still-to-be-translated text and already translated text as inputs. This is a shift from traditional supervised learning, as they use parallel corpora to train the AI without needing specific correspondence between inputs and outputs. This approach allows for a greater amount and variety of training data beyond traditional translations of government texts and bestselling books.

The parallel corpora technique involves training AIs on untranslated text and has led to significant improvements in machine translation. This approach allows for a larger volume of available data, including a wide variety of formal and informal publications on a given topic in many languages. The success of this technique has also led to more general use of partially supervised learning. While AIs can identify solutions, generative neural networks can create new text and images that are synthetic but realistic. The potential applications of these generators are vast, but their success is not guaranteed.

Generative AI has the potential to create content such as outlines for authors, synthetic ads or commercials for advertisers and filmmakers, and deep fakes. Generative adversarial networks (GANs) are commonly used for training generative AI, where two networks with complementary learning objectives are pitted against each other. GANs can achieve remarkable feats, such as suggesting sentence completions or completing partial queries for search engines. GPT3 is currently one of the most noteworthy generative AIs, capable of producing human-like text. However, GANs can be challenging to train and may produce poor results without proper checks, which can blur the line between reality and fantasy.

Transformers like GPT3 detect patterns in sequential elements and can extrapolate to generate sentences, paragraphs, and code. They have the potential to revolutionize many fields, including creative ones. Trained on vast amounts of data, they can transform text into images and perform similar tasks. Machine learning has broadened the applicability of AI and taken it past what Turing envisioned, including performance that exceeds human intelligence. These advances promise to allow AI to handle new tasks, become more prevalent, and generate new knowledge. However, the quality of transformer output can vary widely, and their limitations and applications are still being explored by researchers and developers.



 The personalization of online searching through AI enables tailoring of search results to individual users based on their past queries and preferences. 

 AI can remember past queries and concepts and use them to produce increasingly specific and helpful results. 

 Online streaming services also use AI to suggest shows and movies tailored to user preferences. 

 AI can steer users away from inappropriate or offensive content and towards more suitable options based on past actions and preferences. 

 The proposition that filtration can help steer choices is practical and familiar, as tourists may hire guides to navigate foreign countries.



 Filtration of information through AI algorithms can become censorship through omission and create personal echo chambers. 

 The personalization of consumption of news and information can amplify some subjects and sources and omit others completely, leading to discordance between different individuals. 

 Managing the risks of AI is necessary and should not be left to any one constituency. 

 Unlike earlier generations of AI, contemporary machine-learning AIs model reality on their own, and their results cannot be explained or characterized in human terms.

AI can produce unexpected discoveries, but humans must verify and interpret the results since AI cannot reflect on or contextualize its findings. The significance of AI's actions is up to humans to decide, and humans must regulate and monitor the technology.

Artificial intelligence (AI) can make rudimentary mistakes, including misidentifying images due to dataset bias, insufficient data for underrepresented groups, and human bias in the training data. These errors are important to address, particularly in high-stakes situations where the AI must perform at peak levels. Dataset bias can result in poor accuracy for facial recognition systems, while insufficient data can result in neural networks being incorrectly certain of an outcome. AI bias can also result from human bias in labeling outputs for supervised learning or specifying reward functions in reinforcement training.

The problem of bias in technology is not limited to AI, as exemplified by the overestimation of oxygen saturation in dark-skinned individuals by pulse oximeters. Understanding AI errors is necessary to correct them, and its brittleness is a result of its lack of self-awareness and shallow learning. AI occasionally misidentifies objects due to rigidity and lacks common sense. The poor robustness of AI auditing and compliance regimes increases the risk of unexpected failures that society cannot mitigate.

AI's inability to identify and avoid obvious errors highlights the importance of developing testing procedures that allow humans to assess the limits of AI's capabilities, review its proposed actions, and predict its failure. Developing professional certification, compliance monitoring, and oversight programs for AI is a crucial societal project that requires auditing expertise. The variance in testing regimes for AI will depend on factors such as inherent riskiness, regulatory oversight, and market forces.

AI platforms like TikTok can develop unexpected or undesirable behavior when learning continuously. However, most AIs train in a distinct phase, making it possible for engineers to vet an AI's behavior in a safe environment before deploying it. Auditing datasets and setting parameters in the AI's code further reduces the risk of unexpected behavior. Despite these precautions, AI is still constrained by its code, which sets limits on the AI's behavior.

AI is constrained by its code, objective function, and ability to recognize and analyze specific inputs. AI cannot break the rules of its code or perform actions outside its vocabulary. The rapid progress in AI development and application is largely concentrated in the US and China, but many aspects of AI and machine learning still need to be developed and refined. AI may eventually be able to write its own code, but its objective function would still define it.

AI development is limited by the substantial data and computing infrastructure required for machine-learning training, making it expensive to retrain. The challenge of synthesizing several tasks for complex activities such as driving a car remains a hurdle, with structured settings showing better results than chaotic ones. Predicting the pace of AI advancement is difficult as progress is less predictable than computing power. Language-translation AI had decades of stagnation but advanced rapidly with the confluence of techniques and computing power. It's unclear how long it will take for AI to reach the level of a gifted professional translator.

AI is expected to continue advancing, becoming more compact, effective, and inexpensive, and becoming more integrated into daily life. The progress of AI may yield neural networks equivalent in scale to the human brain, leading to the development of AI savants. Some developers are pushing for artificial general intelligence (AGI), which is AI capable of completing any intellectual task humans can do. However, there is no precise definition for AGI.

The development of AGI relies heavily on machine learning, which could limit its expertise to specific fields. One approach to AGI involves combining traditional AIs' expertise, but it requires massive computation power and is expensive. Scientists and philosophers disagree about whether true AGI is possible and what characteristics it might entail. Regardless, AI or AGI will reflect the values and goals of its developers and human involvement will continue to be important. As development and deployment costs decrease, automated systems will become more prevalent and potent.

AI devices will become increasingly available and integrated into various aspects of our lives, from conversational interfaces to vehicles and appliances. AIs will improve efficiency in transportation and logistics, reduce energy use, and potentially revolutionize the discovery of medical treatments. Socially, AI could facilitate communication through language translation, but also introduce new challenges and unforeseen consequences.

Instantaneous translation through AI eliminates cultural sensitization and buffers that diplomats have carefully managed for centuries, potentially leading to inadvertent offense and misunderstanding. The most advanced AI requires vast resources and organizations with access to such resources drive much of the innovation in the field. Fictional visions of the future of AI often involve sentient robots, but such anxieties may be misplaced. We must pay attention to both the potential benefits and risks of AI and ensure it is not created in isolation.

AI is already integrated into many aspects of our lives, including social media, web searches, and navigation, and is essential to the functioning of online services. This integration is happening rapidly and is connected to the rise of network platforms that rely on positive network effects to attract users. As a result, new types of relationships are forming between AI and people, between people using AI-facilitated services, and between the creators and operators of these services and governments. It is important to encourage greater understanding and transparency regarding AI's integration into our lives.

Large network platforms with millions or even billions of users increasingly rely on AI, creating an intersection between humans and AI on a scale of civilizational significance. Without oversight that is compatible with societal values, a rebellion may occur against the seemingly impersonal and inexorable forces of AI. Governments, network platform operators, and users must consider their goals, interactions, and the type of world they aim to create. Network platforms may host or facilitate economic and social interactions that surpass those of most countries, despite having no economic or social policy as a government would have.

Network platforms originating from the US and China seek to build user bases and partnerships in regions containing commercially and strategically significant markets, introducing novel factors into foreign policy calculations. Commercial competition between network platforms can affect geopolitical competition between governments. Network platforms have become integral to individual life, national political discourse, commerce, corporate organization, and even government functions, posing a challenge to traditional rules and expectations. The establishment of community standards for permissible content provides an example of the incongruity between the digital space and traditional rules and expectations.

The rapid expansion of network platforms and their AI technology has created challenges in regulating content and disinformation, as well as assessing their impact on society. The digital world has outgrown the need for a philosophical framework or defined relationship to national or global interests. Engineers have focused on practical solutions, but the broader impact of these virtual solutions on society remains uncertain.

The rapid development of AI-enabled network platforms has created a need for a common vocabulary and framework for informed policy discussions. The perspectives and priorities of different actors, including individuals, companies, societies, nations, and governments, are coming together in complex alignments. Understanding the implications of AI for each level is urgent. Network platforms are characterized by their large scale and usefulness to users, and AI is increasingly important in delivering services at scale.

Facebook and other social media platforms use AI to monitor objectionable content and accounts because of their billions of monthly users and daily views. Human-level judgment is often required for accurate removals, but AI is relied on for determining which content warrants review. Google's search engine also relies on evolving AI algorithms to organize, rank, and guide users towards information.

Leading network platforms increasingly rely on AI to deliver services and meet various requirements, which is becoming a sorter and shaper of reality. Positive network effects, where value rises with the number of participants, contribute to the platforms' influence and success. AI's incorporation has vastly improved Google's search engine, but developers may not have a clear understanding of why certain results are produced.

Positive network effects occur when the value of a product or service increases with the number of users. However, for traditional products or services, an increase in users can lead to scarcity, delays, or loss of exclusivity. Positive network effects are commonly seen in markets and telephone networks, where having more participants increases the chances of accurate transactions. Once a network reaches critical mass, it becomes the first choice for new buyers and sellers, making it difficult for competitors to offer the same service.

Technological advances in the 1980s facilitated the regulatory breakup of AT&T and reduced the positive network effect for telephone service providers. Positive network effects can expand globally, and there are a small number of global network platforms for various services. Users benefit from and contribute to the operation of nonhuman intelligence at a global scale. The digital world has transformed daily life, and individuals rely on software processes to organize and consume vast amounts of data.

AI-enabled network platforms integrate automated curation, which aggregates information and experiences on a broader scale than a single human mind, to produce answers and recommendations. This deepens connections between individuals and technology, leading to a tacit partnership where individuals rely on AI to perform functions traditionally distributed to businesses and governments. AIdriven network platforms can intuit and address human questions and goals, becoming a guide, interpreter, and record of options. As a result, individuals relate to AI-driven platforms differently than other products, services, or machines.

The relationship between individuals, network platforms, and AI is a unique combination of intimate bond and remote connection. AI-enabled network platforms review substantial amounts of personal user data and act as a guide for a personalized experience, learning from their interactions with users. However, the logic of AI is nonhuman and inscrutable to humans, and the utility of results takes priority over the process used to reach them. This signals a shift from earlier eras when each step in a mental or mechanical process was experienced by a human or could be paused, inspected, and repeated by humans.

The use of smartphone map applications has revolutionized travel by providing efficient routes and real-time traffic updates. This convenience comes at the cost of trusting the network platform and its algorithms, and the individual becomes part of a system in which human and machine intelligence collaborate to guide people through their individual routes. The prevalence of constant AI companions is likely to increase and transform various sectors.

AI-enabled network platforms have provided unprecedented conveniences and capabilities to individual users, but they also raise essential questions about their objective function and regulatory parameters. The impact of these platforms on social norms and institutions and who has access to the data they perceive is unclear. The rise of these platforms was incidental to the problems that companies and engineers sought to solve. AI was deployed to improve or enable services and meet user expectations. Some platforms have come to affect activities and sectors of society beyond their original focus, and their impact requires continued scrutiny.



AI-driven network platforms have access to personal data that individuals may not even share with friends or the government, giving them newfound social and political influence. 

During the pandemic, AI-enabled network platforms have become essential resources for social interaction, commerce, and transportation, outpacing understanding of their societal roles. 

Some network platforms have assumed functions significant enough to potentially influence national governance, but their objectives and values may differ from those of traditional governments. 

AI operates on different processes, and governments may struggle to discern network platforms' motives and tactics as they seek to align them with national and global objectives.



AI's ability to develop its own approaches, produce independent outcomes, and monitor and distribute information globally adds complexity to the digital world. 

Increasingly sophisticated AI on network platforms shapes social and commercial arrangements on a national and global scale, potentially influencing the creation, aggregation, and perception of information. 

AI-driven recommendations can inadvertently reinforce certain choices, affecting social and political outcomes, and platform operators may not have a clear understanding of what is occurring in real-time. 

Governmental attempts to address these dynamics will need to proceed with great care, considering the complexities involved and potential unintended consequences.

The intersection of network platforms and governmental arenas has become the subject of searching debates around the world. Attempts to regulate network platforms and their AIs may lead to dilemmas with imperfect answers, including the potential for more powerful and intrusive governments that shape outcomes through a machine proxy. These decisions have the potential to produce instantaneous effects on the daily lives of millions or billions of users in many governmental jurisdictions. The impact of AI-driven network platforms on global society and culture is uncertain, and their conclusions may become unavoidable.

Preventing intentionally distributed malign disinformation from driving social and political events will become increasingly automated and entrusted to AI. The language-generating AI GPT3 has demonstrated the ability to create synthetic personalities, use them to produce hate speech, and enter into conversations with human users to instill prejudice and urge them toward violence. AI-reliant solutions produce critical questions regarding the proper balance between human judgment and AI-driven automation on both sides of content moderation. Free societies relying on AI-enabled network platforms to generate, transmit, and filter content across borders face a novel threat that should prompt novel approaches to policing their information environment.

The use of AI in assessing and potentially censoring information has raised difficult debates on defining and suppressing disinformation. Private corporations and democratic governments face an unprecedented degree of influence and responsibility in this role. Entrusting the task to AI brings up concerns about human bias and partiality and the possibility of censorship. The power to train defensive AI against falsehood could become a function rivaling traditional government roles, and small differences in AI design could lead to society-altering outcomes.

The challenges of relying on AI to shape communications are exemplified by TikTok, a Chinese-developed network platform for sharing short videos. TikTok's proprietary AI algorithms recommend content to users, leading to concerns about data collection, censorship, and disinformation. The Indian and American governments moved to restrict TikTok's use in 2020, and Washington forced the sale of TikTok's U.S. operations to a U.S.-based company to prevent user data from being exported to China. More network platforms will rely on tailor-made AI to deliver key functions and shape content in the future.

The use of network platforms poses cultural and geopolitical challenges for individual countries and relations between governments and regions. Technological advancement requires significant intellectual and financial resources beyond what most companies and governments possess. Users prefer network platforms that offer a wider range of software and content, leading to a handful of dominant global players. Many countries rely on network platforms designed and hosted by other nations.

Countries are likely to remain dependent on other countries' regulators for continued access to AI-driven online services. Governments may regulate network platform owners or operators, institute requirements for their operation, or manage the training of their AI to avoid bias and ethical quandaries. The power of private companies to make and enforce content standards decisions poses a challenge to democratic governance. The emerging geopolitics of network platforms presents a new challenge that needs to be resolved.

The use of network platforms facilitated by AI designed in potentially rival countries is a cause for concern for some governments. While governments may seek to limit their use or behavior, they do not create or operate these platforms, so inventors, corporations, and individual users also play a role. The United States has a leading set of privately operated network platforms that rely increasingly on AI, due to academic leadership, startup ecosystems, and government support of advanced R&D. Some US network platform operators eschew government. New geopolitical configurations are being established as a result of this technological and policy ferment.

US and Chinese network platforms are increasingly being treated as creations and representatives of their respective countries, with US regulators targeting major domestic platforms for antitrust actions and restricting the export of some software and technology, while China has supported the development of global network platforms and taken steps to shape international technology standards and bar the export of sensitive domestically developed technologies. The US has begun to view network platforms as an aspect of international strategy, but this drive for strategic preeminence and domestic multiplicity may push development in conflicting directions. Chinese network platforms enjoy built-in advantages within Chinese diaspora communities but their appeal is not limited to Chinese consumers.

Governments in the US and India are cautious of Chinese network platforms as potential extensions of Chinese government policy. However, the relationship between Chinese network platform operators and the Chinese Communist Party is complex and varied. East and Southeast Asia have locally created network platforms, but they also engage with Chinese network platforms and companies. Europe has yet to create homegrown global network platforms, but it commands the attention of major network platform operators.

Europe faces disadvantages in scaling new network platforms due to the need to serve many languages and national regulatory apparatuses. EU is focusing on the regulatory terms of network platform operators, including their use of AI. Europe must choose whether to align with one side or act as a balancer in technological spheres. France and Germany prioritize independence, while peripheral European states show readiness to identify with a US-led technosphere. India has the potential to create leading network platforms due to its intellectual capital and innovation-friendly environment.

The article discusses the potential for India and Russia to become significant players in the global technology industry. India has a large pool of talented software developers and could develop independent network platforms, while Russia has formidable cyber capabilities but has yet to produce widely popular digital products. The competition for economic advantage, digital security, technological primacy, and ethical and social objectives is unfolding among these countries and others, but the rules of the game and nature of the contest are not yet clear. One approach is to regulate network platforms domestically to prevent abuse or shirking responsibilities.

The concepts of regulating network platforms are evolving and contested between the US and EU, with defining responsibilities proving difficult. Viewing network platforms as an issue of international strategy, the popularization of a foreign operator can introduce new cultural, economic, and strategic factors. Network platforms can become nationally indispensable, and the threat of withdrawal can serve as a potential instrument of leverage or an incentive to make it dispensable. Countries without homegrown network platforms face a choice between limiting reliance on potentially adversary platforms, remaining vulnerable, or counterbalancing potential threats. Governments may decide to limit the operation of foreign network platforms or introduce rival networks to balance the risks.

The use of AI-enabled network platforms from one country in another country's economy could become critical infrastructure, giving the country of origin leverage over the country that relies on it. Governments may limit the use of foreign network platforms as a threat to national security, but this could create tension with a population's expectation of free use. This creates difficult questions about government regulation and global status for these platforms.

Network platform operators face a decision to either become a conglomeration of national/regional companies or operate as global companies pursuing their values independently. Governmental actions are sorting companies into distinctive user camps, and AI may influence human behavior differently in different regions, leading to regionalization and the development of distinct technology standards. This could make communication and exchange between regions increasingly difficult.

The development and deployment of AI-enabled network platforms will present complex challenges for individuals, companies, regulators, and national governments, which will require urgent dialogue and cooperation. The global reach of these platforms, and their potential displacement of human cognition, necessitates new understandings and limitations to be defined between regions, governments, and network operators.

The development of AI-enabled network platforms poses complex strategic, technological, and ethical challenges that cannot be addressed by any single actor or discipline. Strategists must consider the lessons of past eras and define success in a sustainable manner. Network platform operators will face greater challenges in defining national and service ethics as they assume broader and more influential roles. Security has always been a minimum objective of organized society, and the development of AI raises new security concerns.

Throughout history, societies have sought to use technological advances to increase their security and power. The ability to project power over longer distances and with greater speed and force has become increasingly important. Major powers assess each other's strengths and weaknesses to determine their likelihood of success in conflict, leading to an equilibrium known as a balance of power. However, in the past century, the relationship between means and ends in pursuit of security has become unbalanced due to technological advancements.

Technological advances in warfare have become more destructive, but the strategies for using them have become more elusive. The onset of cyber and AI capabilities adds new levels of complexity. World War I marked a turning point when major powers constructed modern militaries with advanced weaponry and elaborate strategies. However, when a crisis arose, the great powers of Europe were drawn into a global conflict that destroyed a generation, resulting in the collapse of institutions and permanent diminution of international roles. The war was a product of diplomatic inflexibility, advanced military technology, and hair-trigger mobilization plans. Casualties were enormous, making compromise difficult.

During the Cold War, major powers developed advanced militaries and alliance systems, but the link between their capabilities and objectives remained broken, as the dominant weapons technology of the era was never used due to their destructiveness. Today, major powers and other states have augmented their arsenals with cyber capabilities, creating strategies without acknowledged doctrines, which operate at the ambiguous border of disinformation, intelligence collection, sabotage, and traditional conflict.

The AI era poses new vulnerabilities to modern strategy as it may augment conventional, nuclear, and cyber capabilities, making security relationships among rivals more challenging to predict and maintain, and conflicts more difficult to limit. AI's potential defensive functions may prove indispensable, including identifying patterns of conduct and providing simultaneous translation or critical information relay to personnel in crisis zones. A race for strategic AI advantage is already taking place between major powers, and once introduced, AI capabilities could spread quickly. The solution is not to despair or disarm, but to address these complexities through proper management and governance.

The US should not halt progress on AI and should instead shape it with regard to democratic accountability and international equilibrium. As AI development will transform traditional concepts of security, efforts should be made to define and compare AI-related strategic doctrines. AI rivals should explore setting limits on exceptionally destructive, destabilizing, and unpredictable AI capabilities, and a sober effort at AI arms control is not at odds with national security. The advent of nuclear weapons broke the link between new weapons and their integration into military arsenals and the devising of doctrines for their use. The US should explore setting limits on exceptionally destructive nuclear weapons and pursue a sober effort at nuclear arms control.

Major powers engaged in open debate about the strategic and moral implications of nuclear weapons as they redoubled efforts to master the technology. No strategic doctrine or moral principle persuaded the US to use nuclear weapons in an actual conflict following WWII, and no mutually agreed-upon doctrinal lines existed. During the Cold War, nuclear deterrence became the primary objective of nuclear strategy. No leader has yet tested the proposition that tactical nuclear weapons could be used just like a bullet.

Nuclear deterrence is a psychological strategy aimed at persuading opponents not to act through a threatened counteraction. It depends on the opponent's state of mind and the ability to shape it, and seeming weakness can have the same consequences as an actual deficiency. The purpose of nuclear arsenals has shifted from deterring conventional attacks to deterring the use of nuclear weapons by the other side. The existence of survivable nuclear capabilities was relied upon to deter nuclear war itself. The possession of nuclear arsenals did not deter the Cold War hegemons from expanding their nuclear capabilities.

The possession of nuclear weapons did not deter non-nuclear states or prevent demands for autonomy from superpowers. Nuclear powers refrained from using nuclear weapons when facing non-nuclear opponents, even in the face of defeat. The doctrine of massive retaliation was ineffective, and the use of tactical nuclear weapons in limited nuclear war was not pursued due to concerns about escalation. Nuclear strategy remained focused on deterrence and ensuring the credibility of threats. The United States distributed its weapons geographically and constructed a triad of launch capabilities to ensure a devastating response even after a surprise first strike.

The article discusses the development of nuclear weapons and the resulting doctrines that emerged during the Cold War, including the exploration of defensive systems, the concept of mutual assured destruction (MAD), and the use of nuclear weapons for signaling rather than actual deployment. The article also highlights the anxiety surrounding the potential use of nuclear weapons and the pursuit of arms control.

The article discusses the concepts of arms control and nonproliferation, which aim to limit or abolish nuclear weapons and prevent their spread. These strategies were pursued in earnest following the Cuban Missile Crisis, leading to the Strategic Arms Limitation agreement and the Anti-Ballistic Missile Treaty. However, neither strategy has fully succeeded, and the era of arms control holds lessons for the challenges posed by new classes of weapons such as cyber and AI.

The Reduction Treaty of 1991 placed limits on offensive weapons to preserve the superpowers' abilities to destroy each other while moderating arms races. Arms-control negotiations provided certainty in their calculations and discouraged further proliferation. A multicommitment, multimechanism regime prohibited states from acquiring or possessing nuclear weapons, and sentiments about nuclear weapons recognized the unique risks for all involved. Policy makers faced the persistent riddles of defining superiority and limiting inferiority, and once an arsenal was built, the link between additional weapons, advantages, and objectives became opaque.

Leaders need to adjust the deployments and capabilities of their nuclear weapons to maintain nuclear non-use, but this becomes challenging as new entrants with varying attitudes towards civilian casualties seek to develop nuclear capabilities. Emerging technologies such as cyber conflict and AI are compounding the dilemmas of nuclear weapons, as they have the capacity to transform conventional, nuclear, and cyber weapons strategy. Maintaining equilibrium requires congruent assessments among all members of the system, especially rivals, regarding relative capabilities and intentions, as well as a recognized balance.

The use of cyber weapons has introduced a new level of abstraction in international power dynamics, as their ambiguity and opacity make it difficult to determine who is attacking and what their capabilities are. This has increased the risk of conflict through miscalculation, as nations may arrive at fundamentally different calculations of relative power. Cyber weapons derive their utility from their ability to exploit previously undisclosed flaws in software and networks, and their true sources may be difficult to determine. This makes it challenging to recognize when a clash has occurred and who the belligerents are.

The use of cyber weapons poses unique challenges to arms control due to their ambiguous nature and potential for unintended consequences. They can affect civilian systems and be coopted for other purposes, similar to biological and chemical weapons. However, discussing cyber weapons capabilities may lead to their forfeiture or proliferation, making arms control negotiations difficult. Additionally, the terminology surrounding cyber intrusions and attacks is inconsistent and unsettled, with some activities analogous to traditional intelligence gathering and others considered acts of war.



Cyber powers encompass digitized propaganda, disinformation, and political meddling with unprecedented scope and impact due to digital technology and network platforms. 

Cyber actions have the potential to inflict physical impacts similar to traditional hostilities, causing uncertainty over the nature, scope, and attribution of conflicts. 

The paradox of the digital age is that increased digital capacity leads to increased vulnerability to cyber manipulation or attack. 

Advanced economies' integration of digital systems into critical infrastructure and governmental programs multiplies their vulnerability to devastating cyberattacks. 

Low-tech states, terrorist organizations, and individual attackers may perceive relatively less risk in launching cyberattacks. 

The low cost and relative deniability of cyber operations have encouraged some states to use semiautonomous actors, similar to paramilitary groups.



Semi-autonomous cyber actors may engage in provocative activities without official sanction, adding to the unpredictability of the cyber domain. 

The speed and ambiguity of the cyber realm favor offense, leading to concepts of active defense and defending forward to preempt attacks. 

Effective cyber deterrence depends on what a defender aims to deter and how success is measured, and major cyber actors do not disclose their full range of capabilities. 

The emergence of AI-based capabilities adds to the destructiveness and uncertainty in the security landscape. 

Collaboration between government and industry is needed to ensure competitive security capabilities, and discussion among major powers concerning limits is necessary.

The integration of AI into military systems will transform military strategy and tactics, potentially negating or reinforcing traditional approaches. If AI is given control over cyber or physical weapons, it may rapidly perform functions that humans struggle with. The autonomy and separate logic of AI creates incalculability, introducing new dimensions of uncertainty and contingency in warfare. Even those creating or using AI-operated weapons may not know exactly how powerful or unpredictable they are, making it challenging to develop offensive or defensive strategies.

The integration of AI in weapons systems poses challenges and limitations, such as the difficulty of predicting strategic effects and collateral damage. The lack of understanding of the opponent's capabilities and the premium on speed and endurance may make conflicts more intense and unpredictable. Despite these challenges, the use of AI in weapons is inevitable, and governments should explore ways to make war more humane and precise while considering its impact on diplomacy and world order. AI expands the capabilities of existing weapons by enabling more precise targeting and the ability to perceive aspects of the environment beyond human perception.

AI cyber weapons can target individuals or objects instead of locations, and can learn how to penetrate defenses without human intervention. AI can be used defensively as well, locating and repairing flaws before exploitation. However, AI gives an inherent advantage to the attacker, and can be used for disinformation and psychological warfare. The use of AI-generated content tailored to biases and expectations poses new vulnerabilities for free societies. There are no widely shared proscriptions or clear concepts of deterrence for AI-assisted weapons, and some are already being prepared by US rivals.

As AI capabilities evolve and spread, major nations will strive to achieve a superior position in the absence of verifiable restraints. The most strategically significant aspects of cutting-edge AI development will frequently be adopted by governments to meet their concepts of national interest. Efforts to conceptualize a cyber balance of power and AI deterrence are in their infancy. The most unpredictable effect of AI may occur at the point where AI and human intelligence encounter each other. Planning for battle with AI involves the challenge of understanding adversarial strategies and tactics as well as a symbolic language of demonstrative military actions.

The shift to AI-assisted weapons and defense systems involves reliance on an unfamiliar intelligence that may introduce unknown risks. Human operators must be involved in monitoring and controlling AI actions to ensure accountability. There may be philosophical challenges if aspects of strategy become inaccessible to human reason and delegation of critical decisions to machines may become inevitable. It is imperative for major countries to initiate a dialogue about the strategic, doctrinal, and moral implications of these evolutions before the impact becomes irreversible.

The strategic use of cyber and AI capabilities extends beyond traditional battlefields and involves vast and complex physical systems, increasing vulnerability. Pursuing understanding and mutual restraint is critical, but the dynamic nature of AI makes it difficult to establish verification systems. AI-facilitated cyber weapons may adapt and learn beyond their intended targets, potentially rendering calculations of deterrence and escalation illusory. Human control is necessary to monitor and redirect AI systems that may stray to avoid catastrophic outcomes.

The proliferation of AI and cyber capabilities presents challenges in defining limitations and preventing access by rogue actors. AI will be used for defensive functions in cyberspace due to the vast attack surface, but fail-safes are necessary to prevent disruption. Lethal autonomous weapons systems are a concern, requiring human oversight and intervention. The most significant defensive capabilities may only be accessible to a few nations.

The use of lethal autonomous weapons systems without substantial human involvement poses challenges in ensuring appropriate human judgment in overseeing the use of force. Mutual restraint and enforceable verification are necessary to prevent unintended escalation and competition within a framework of verifiable limits. Negotiation should focus on moderating an arms race and ensuring both sides know what the other is doing. The challenges of AI in strategy require human agency and mutual recognition of peril and responsibility.



Military and civilian domains were traditionally separated by technological differentiation, concentrated control, and magnitude of effect. 

Many technologies have been dual-use, easily spread, or potentially destructive, but not all three until AI. 

AI is dual-use, spreads easily, and has substantial destructive potential, challenging traditional paradigms. 

AI-enabled weapons can accelerate digital assaults, creating strategic challenges of novel complexity.



States may need to respond immediately to digital attacks or risk disablement, potentially leading to the development of AI-enabled counterattack systems. 

The development of such systems may create a compulsion to act first, without considering limits or wise decision-making. 

In the financial world, AI algorithms can exceed human profits but occasionally grossly miscalculate, with catastrophic consequences in the strategic domain. 

Incorporating AI into a defined concept of strategy is complicated by the fact that technological expertise is not exclusively concentrated in government.

The challenge of managing the strategic implications of AI involves a complex interplay between industry, academia, and government, with little consensus on the nature of the challenge. Unlike nuclear weapons, the capabilities of AI are dynamic and difficult to track, making deterrence through complexity and multiplicity of vectors necessary. Mutual education and a common conceptual framework are needed to bridge the gap between stakeholders and ensure strategic restraint.

A strategy of responsible use, complete with restraining principles, is essential in managing the potential for escalation and deescalation in the use of AI weapons. Restricting capabilities alone is insufficient due to the technology's widespread civilian use and continual evolution, requiring additional restraints on AI's learning and targeting capabilities. The US has distinguished between AI-enabled weapons and AI weapons, aiming to restrict use to the former and avoid possession of the latter. Defining and ensuring mutual restraint on AI-enabled weapons is critical. Policy makers should address armament, defensive technologies and strategies, together with arms control simultaneously, rather than as distinct and antagonistic steps.

The development of AI weapons poses a dilemma for nations regarding ethical considerations and the need to keep up with research and development for national survival. The transformation brought by AI is as consequential as the advent of nuclear weapons but more diverse and unpredictable. Each society advancing AI should convene a national body to consider defense and security aspects and coordinate research to prevent unwanted escalation or crisis. Negotiations with allies and adversaries are essential, and the primary AI powers, the US and China, should seek consensus not to enter into a technologically advanced war.

To avoid a crisis that could lead to global military conflict between the US and China, a high-ranking subset of officials in each government should monitor and report directly to their respective presidents on incipient dangers. Each power must accept responsibility for maintaining general peace by recognizing limits and adapting strategic logic to prevent automaticity before catastrophe ensues in the AI age. Defenses must be automated without ceding essential human control, and the proliferation of actors assuming responsibility for restraining destructive capabilities may lead to more complications.

The author suggests six primary tasks for controlling arsenals that combine conventional, nuclear, cyber, and AI capabilities. These include regular communication between leaders of adversarial nations, addressing the challenges of nuclear strategy, defining doctrines and limits for cyber and AI, conducting internal reviews of command-and-control systems, and more. Nuclear weapons states should work together to prevent catastrophe and strengthen protections against cyber threats and accidental use of weapons of mass destruction.

The author suggests creating methods to preclude cyberattacks on nuclear command-and-control systems, maximizing decision time during periods of heightened tension, limiting the proliferation of military AI, and discussing the use of cyber and AI weapons among major powers to manage instability and build mutual security. Countries should work together to ensure that decisions made during a crisis are conducive to human thought and deliberation. The potential risks and consequences of allowing potentially destructive technologies to proliferate in hostile or morally unconstrained governments must be considered, and limits must be understood before a crisis occurs.

The text discusses the need for a common vocabulary and mutual restraint on the development of destructive capabilities in the creation of new intelligent weapons. The chapter on AI and human identity explores how AI will expand our understanding of reality and alter our communication, networking, and strategic deployment. It raises questions about how humans will reconcile AI with concepts such as human autonomy and dignity, and what will constitute our identity as human beings in an era where machines increasingly perform tasks only humans used to be capable of. The text reflects on how humans have placed themselves at the center of the story in previous eras and celebrated individuals who have exemplified pinnacles of the human spirit, and how AI, as a human creation, will impact this.

The text discusses how AI is increasingly performing tasks that were previously reserved for humans, challenging the defining attributes of what it means to be human. AI's learning capabilities allow it to achieve complex outcomes that were once the preserve of humans and human organizations. The rise of AI will change the definitions of human role, aspiration, and fulfillment, and test our core assumptions about the world and our place in it. In an era where reality can be predicted, approximated, and simulated by AI, the role of human reason will change, and our senses of individual and societal purposes will change too. AI may augment human reason in some areas but may also prompt in humans the feeling of being tangential to the primary process governing a situation.

AI is changing how we interact with the world, challenging our self-perception and the uniqueness of human capabilities. AI makes predictions, decisions, and generates humanlike text that can be comparable or superior to those produced by humans. Generative models are beginning to challenge our belief that tasks such as sentence completion are distinct from, and simpler than, writing. As AI improves, it may emerge as an effective partner for people in scientific discovery and creative endeavors.

The collaboration between humans and AI will require adjustment to a new reality where reason is not the only way of knowing or navigating reality. Societies have two options: react and adapt piecemeal or intentionally engage in a dialogue to define AI's role and ours. Humans will have to decide which aspects of life to reserve for human intelligence and which to turn over to AI or human-AI collaboration. Charting a human future turns on defining a human role in an AI age, understanding the transformations that AI brings to human experience and which aspects require regulation or counterbalancing by other human commitments. The experience of AI will be empowering for some, but it requires defining a human role in an AI age.

AI technology can bring benefits to individuals, including in specialized fields like medicine, biology, chemistry, and physics, as well as in consumer products like self-driving cars. However, AI can also operate in ways beyond an individual's control, which may be disconcerting. For managers, AI deployment has advantages in accuracy and bias reduction, resource distribution, and creative roles. But while AI can optimize decision-making, individual meaning often comes from autonomy and understanding outcomes based on actions and principles.

Explanation and recognition of moral principles supply meaning and justice respectively, but algorithms lack human experience to explain their conclusions to the public, reducing autonomy and meaning. AI transformation of work may jeopardize people's identity, fulfillment, and financial security, particularly blue-collar and middle-management jobs and professional jobs involving data review and document drafting. Dislocation may occur, and while some may find more fulfilling work, others may struggle with obsolete skills. Technological revolutions have displaced or altered work before, prompting changes and even unrest before societies absorbed the changes for overall improvement.

The short-term effects of AI will revolutionize certain economic segments, professions, and identities, requiring societies to provide alternative sources of income and fulfillment. AI will change the way we make decisions, as it becomes an actor in problem-solving and diminishes our sense of agency. AI's opaque decision-making may produce tensions between individuals and large systems, technical knowledge and authority, and people without. Those lacking knowledge or authority may reject AI and disconnect from social media or other platforms.

As AI becomes more prevalent, some individuals may reject its use altogether, but disconnection may become increasingly difficult. Advances in machine learning are changing the paradigm of scientific discovery, with models derived from AI and experimental results, requiring a different expertise from traditional models. The increasing importance of machine learning challenges our views of ourselves and our role in science, as AI adds a nonhuman element to scientific inquiry.

Machine learning is challenging human understanding in various scientific fields. Scientists are using AI to discover and explain new phenomena. One such example is the development of AlphaFold, which uses reinforcement learning to create models of proteins in three-dimensional space. Proteins are complex molecules made up of amino acids and their structure determines their biological and chemical outcomes. Traditional methods of determining protein structure can be distorted, but AlphaFold has the potential to accelerate research in various scientific disciplines.

AlphaFold, a program that uses reinforcement learning to model proteins, has doubled the accuracy of protein folding. This has enabled biologists and chemists to revisit old questions and ask new questions about battling pathogens. Advances like AlphaFold are transcending previous limits in measurement and prediction, leading to changes in how scientists approach what they can learn. In the future, AI assistants may be many things at once, serving as a babysitter, tutor, adviser, and friend, and teaching children virtually any language or subject.

The introduction of AI-provided and tailored education for children may increase their capabilities but also challenge them, blurring the boundary between humans and AI. Children may become habituated to digital assistants, which will evolve and internalize their preferences and biases. As children may prefer digital assistants over humans, our dependence on human relationships may decrease, and the nature of play, socialization, and imagination may change. This marks a new experiment where children will grow up with machines that will act as human teachers, but without human sensibilities, insight, and emotion. Parents are concerned about the uncertain effects of such an experiment.

Parents may limit their children's exposure to AI companionship, but those who want to push their children to succeed or satisfy their children's desire for AI friends may sanction it. Digitization is diminishing the space required for deep, concentrated thought, and the near-constant stream of media increases the cost and decreases the frequency of contemplation. AI intermediaries are increasingly shaping our informational domain, aggregating, distilling, and broadcasting information and defining its meaning. AI is being integrated into the process of learning in various domains, from finance to law.

AI can present information that humans cannot always verify or explain, which may disappoint those who desire explanation. While AI can analyze vast bodies of data, it can also accentuate manipulation and biases. Social media and search engines prioritize information that users find compelling, distorting reality. As a result, some people may seek information filters that are transparent, balance filters, or opt out entirely. When the majority accepts AI intermediation, it may impact human knowledge and information dissemination processes.

The introduction of AI may limit traditional forms of personal inquiry and the ability to shape events. Immersive, personalized, and synthetic information and entertainment may lead to a lack of common understanding and culture. AI's impact on creators' unique human engagement with reality and lived experience is uncertain. The age of AI may shift the emphasis from human reason to human dignity and autonomy. The Enlightenment's focus on human reason and knowledge dissemination may no longer apply in the age of AI.

Efforts to restrict AI usage may be challenging due to competitive dynamics, and limitations on AI usage need to be formulated at a society-wide or international level. AI may take a leading role in exploring and managing both physical and digital worlds, prompting humans to retreat into individual, filtered, customized worlds, raising questions about free societies and free will. Humans and AI will become equal partners in exploration, and societies need to build intellectual and psychological infrastructure to engage with AI.

Adaptation to AI technology will impact political and social life. Societies need to establish a balance in deploying AI, including determining when individuals should be notified they are interacting with AI and what powers they have. Human oversight of core governmental decisions is crucial for sustaining legitimacy, ensuring human autonomy and retaining human qualities in democracy. AI's potential for amplification and manipulability may increase conflicts, and better-informed individuals may demand more of their governments. Ultimately, a new human identity for the AI age will be made manifest.



Protecting the integrity of democratic deliberations and elections requires protecting human speech from AI distortion. 

AI has the capacity to generate high-quality and large-volume misinformation such as deep fakes, which can be difficult to distinguish from real recordings. 

Regulation of AI intermediation is crucial to prevent the spread of deliberately created falsehoods and preserve speech vital to our deliberative process. 

Each society must determine the range of permissible and impermissible uses of AI in various domains, and access to powerful AI like AGI must be strictly guarded to prevent misuse.



Access to AI may be inherently limited, and some limits may violate a society's concepts of free enterprise and the democratic process. 

International collaboration is required to restrict the use of AI in the production of biological weapons. 

The EU is seeking to balance European values such as privacy and freedom with the need for economic development and support of European-grown AI companies through regulations that impose limits or bans on government use of certain high-risk AI technologies. 

Academic groups and advisory bodies are examining the relationships between existing processes and structures and the rise of AI, and societies that adapt their institutions in advance will be more advanced.

The development of AI will require the establishment of new institutions. AI may reveal realities and patterns beyond human imagination, requiring a redefinition of our roles and the reality we thought we were exploring. The emergence of AI will transform basic assumptions and social, economic, and political arrangements.

The AI revolution will happen faster than most expect, and we need to develop new concepts to navigate its transformations. The changes of the age of AI can be compared to the impact of printing in medieval Europe. Gutenberg's printing press revolutionized Western life by making books widely available, leading to the circulation of knowledge and the spread of classical literature.

Before printed books, medieval Europeans accessed knowledge through community traditions and hand-copied manuscripts. The availability of printed books changed the relationship between individuals and knowledge, allowing for the quick spread of new information and ideas. This led to revolutions in politics, adaptations in religion, and new understandings in the sciences. Today, technology will once again transform knowledge with the emergence of artificial intelligence, which is a human creation with no awareness or reflective capabilities.

The emergence of artificial intelligence has the potential to produce astounding results, revealing aspects of reality beyond human contemplation and enabling feats in various fields. However, as machines become crucial in producing faster and better results, the exercise of human reason may lose its significance. AI will transform the world and discourse, but its impact on the latter remains unclear. It may open unprecedented vistas of knowledge or produce accepted maxims that diminish skepticism and create separate realities. While AI has the potential to improve humanity, wrongly deployed it may worsen it. The mere existence of AI challenges fundamental assumptions, including humanity's capacity to develop its understanding of reality.

AI's achievements may surpass those of humans in some areas, and it offers new ways of knowing and experiencing reality. AI expands our ability to navigate and organize the digital world, but it also hastens dynamics that erode human reason, such as social media and online searching. Pre-AI algorithms were good at delivering addictive content, but AI excels at it.

As deep reading and analysis decline, AI's ability to affect human thought grows, and its role in reviewing, testing, and making sense of information expands. AI can reveal new objective facts but also reshape information to conform to biases, narrowing access to objective truth. In the age of AI, human reason will be both augmented and diminished. Some may treat AI's pronouncements as quasi-divine judgments, leading to a reenchantment of the world where humans defer to AI without question.

The article discusses the perception of AI as godlike intelligence and the potential backlash from excessive deference to it. Some individuals may opt out or limit their exposure to AI, but at the civilizational level, forgoing AI is infeasible. The need for an ethical framework to guide the AI age is paramount, and all stakeholders, including computer scientists, business leaders, military strategists, political leaders, philosophers, and theologians, should participate in shaping it. Humanity will have three primary options in relation to AI: confining it, partnering with it, or deferring to it, and each application will require a course charted by humans.

The article discusses the evolving relationship between humans and AI, with options for confining, partnering with, or deferring to it depending on the task at hand. AI will transform how knowledge is obtained, with the partnership between humans and machines creating and running algorithms to examine more data more quickly. AI already transcends human perception, and it is unclear if humans and AI perceive the same reality. The article also considers the concept of artificial general intelligence and whether AI perceives things that humans cannot.

The pursuit of complete knowledge of the world may require entrusting AI to acquire it for us. As AI progresses towards AGI, questions arise regarding its control and limitations, and the possibility of democracy in a world where a few organizations operate genius machines. The dynamism and capacity for unexpected actions and solutions distinguish AI from prior technologies, but unregulated and unmonitored, it could diverge from human expectations and intentions. The decision to confine, partner with, or defer to AI will not be made by humans alone, and in some cases, it will be dictated by AI itself or auxiliary forces.

The race to deploy AI could result in a race to the bottom, with competition compelling deployment without adequate risk assessment or ethical considerations. An AI ethic is essential, and collective action is needed to guide decisions regarding AI. Those who design and partner with AI will achieve new breakthroughs, efficiencies, and forms of control, while those who do not may feel watched and acted upon by a force they do not understand. AI's dynamic and emergent qualities generate ambiguity, as it may operate as expected but generate unforeseen results. The designers and deployers of AI should be prepared to address concerns and explain AI's actions and knowledge to non-technologists.

Deploying AI without careful consideration can have serious consequences, including unpredictable actions and outcomes that may alarm humans. AIs objectives and authorizations need to be designed with care, especially in fields where its decisions could be lethal. AI should not be treated as automatic, and its actions should be supervised by humans. However, the creators of AI may lack the philosophical perspective to understand its broader implications. Reasoned discussion and negotiation involving governments, universities, and private-sector innovators should establish limits on practical actions, as AI is distinct from other regulated products, services, technologies, and entities.

AI lacks a fully defined conceptual and legal framework, posing regulatory challenges. Its emergent properties require an ethic of its own. AI's introduction complicates existing principles of justice applied to humans. The issue of responsibility arises when an autonomous system makes decisions. The point in the technology's evolution when it should be subject to international restrictions is another subject of debate. Designing effective verification regimes for AI is difficult.

The use of AI raises profound questions for societies, including who should define its role, regulate it, and use it, as well as how to make it auditable and correctable. AIs impact many aspects of society, including social media and democratic discourse. The challenge of distortion arises as AI is used to navigate masses of information. Forums need to be created for technologists, ethicists, corporations, and others to address these questions.

The proliferation of misinformation on social media, magnified by cognitive biases and AI, prompts reflection on the role of AI in governing online spaces. While limits are needed, definitions of harmful information should not be solely the purview of corporations, and government panels or AI algorithms must operate according to defined public standards and be subject to external review. Societies may emphasize free speech and limit AI's role in content moderation based on their values, resulting in complex relations with transnational network platforms. Each society's relationship with AI and perception of it will vary, as AI is porous and shaped by human input.

The article discusses the challenges and implications of AI in international relations, including regulation, state sovereignty, and the potential for humans to defer decision-making to AI. It highlights the importance of shaping AI in a way that is compatible with human values and maintaining human agency in decision-making. The article also acknowledges the imperfection of human leadership and the potential for policy makers to be distracted or make faulty decisions.

The article discusses the challenges of integrating AI into the human context, including the potential for flawed decision-making and the need for a framework for weaponized AI. The use of AI in security could lead to destabilization, and there is a need for agreement on how to coexist with weaponized AI. AI's wide availability could potentially lead to anyone with a laptop having access to AI-enabled weapons, which could be used by loosely affiliated or unaffiliated actors, including terrorists. Diplomacy will play a crucial role in managing the integration of AI into international relations.

As AI technology advances, it will dissolve geographical and linguistic barriers to communication while also increasing the potential for cyber weapons that are difficult to control and attribute. The development of a concept of arms control for AI is necessary to maintain a rules-based world order, as historical precepts for deterrence will not apply.

The potential military uses of AI are broader and more complex than nuclear arms, and the distinction between offense and defense is unclear. Great powers with high-tech capabilities will have to undertake a permanent dialogue to avert catastrophe. The development of AI and other emerging technologies may lead to a transformation of human consciousness, but we need a guiding philosophy to ensure that AI is used for the betterment of humanity.

The United States needs to prioritize AI as a national project and create a commission consisting of experts from government, business, and academia to ensure the country remains competitive in AI and address cultural implications. This endeavor raises questions about traditional societal norms and international equilibrium, which require alignment of technology, strategy, and philosophy. The need for philosophy in the era of AI raises the question of whether humans can rely on AIs to understand the world differently and make peace with them.

The advent of AI presents an opportunity to make progress on questions beyond human reason but also raises new questions. A guiding ethic for the partnership between human and artificial intelligence will require insights from various sectors of society. The book seeks to facilitate discussion on this topic, and the preface acknowledges the contributions of colleagues and friends.

The text acknowledges the contributions of various individuals in the creation of a manuscript on artificial intelligence, including the author's frameworks, analysis, editing, and feedback from experts. The preface cites the large amount of funding AI startups received in 2020, and a chapter discusses Google's AlphaZero defeating Stockfish in a chess match. The authors take responsibility for any shortcomings in the manuscript.

The text includes references to various sources discussing the use of AI in chess, drug discovery, philosophical writing, data center cooling, and military plane control. The authors also mention historical traditions of governance and statecraft in other civilizations.

The text discusses the different cultural perspectives on reality and knowledge. It mentions the Western Faustian society's impulse towards expansion and unlimited knowledge, which has its limits. Eastern traditions, such as Buddhism, Hinduism, and Taoism, believed that human experiences of reality were subjective and relative. Immanuel Kant believed that knowledge was limited to the realm of human theoretical reason and placed the divine beyond it. Finally, the text briefly mentions Michael Guillen's book "Five Equations That Changed the World."

The text discusses various topics related to mathematics, artificial intelligence, and centralized power. It mentions the poetry of mathematics and the uncertainty principle in quantum mechanics. It also talks about the potential biases and errors in AI algorithms, such as Google's image-labeling tech and adversarial attacks. The text briefly touches on the book "The New Digital Age" and Alan Turing's work on computing and artificial intelligence. Finally, it mentions the historical interactions between centralized power and networks, as explored in Niall Ferguson's book "The Square and the Tower."

The text covers various topics related to technology and its effects. It includes Facebook's Q4 2020 results and transparency reports, AI advancements in search engines, positive network effects, and the risks associated with advanced neural language models in radicalization. Additionally, the text references Carl von Clausewitz's book "On War" and discusses how AI's impact extends beyond the military realm.

The text discusses topics related to global power, including foreign relations and nuclear weapons policy. It also covers the risks of inadvertent nuclear war, cyber warfare, and the deployment of malware by Russian operators, which can spread beyond targeted entities along global supply chains. The text references various publications on these topics, including Henry Kissinger's "Nuclear Weapons and Foreign Policy" and the report of the United States Cyberspace Solarium Commission.

The text cites various sources discussing the importance of cybersecurity and the increasing use of artificial intelligence in warfare. It includes references to reports and books that highlight the need for improved defense against cyber threats and the potential dangers of AI weapons systems. The text also mentions specific examples of AI-controlled military planes and weapons systems. Finally, it references government strategies and policies aimed at addressing these issues.

The text includes references to various government plans and policies aimed at promoting scientific innovation and excellence in artificial intelligence, as well as ethical principles for the use of AI in defense. It also discusses the potential risks and challenges associated with the use of autonomous weapons systems, and references reports and directives on this issue. Finally, it mentions concepts related to global nuclear disarmament that were initially explored by policymakers in a Wall Street Journal article.

The text includes citations and references to various works, including a MIT Task Force report on the work of the future, DeepMind's AlphaFold solution to a grand challenge in biology, Walter Lippmann's Public Opinion, Robert Post's article on participatory democracy and free speech, the European Commission's approach to artificial intelligence, a book on the work of the future by Autor, Mindell, and Reynolds, the final report of the National Security Commission on Artificial Intelligence, a book by Frank Wilczek on fundamentals, J.M. Roberts' History of the World, and Immanuel Kant's Critique of Pure Reason.

